{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud in Mobile Money Transactions\n",
    "PaySim simulates mobile money transactions based on a sample of real transactions extracted from one month of financial logs from a mobile money service implemented in an African country. The original logs were provided by a multinational company, who is the provider of the mobile financial service which is currently running in more than 14 countries all around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows us to ignore warnings, since they are just warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# allows us to print things in jupyter in a pretty way\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "# import pandas to be able to use dataframes\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "# import plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# allow inline plotting on notebook cells\n",
    "%matplotlib inline\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "# we'll get access to the numpy library\n",
    "import numpy as np\n",
    "\n",
    "# We'll use a label encoder to convert categorical feature to numerical values\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# install using: pip install outlier_utils\n",
    "# univariate anomaly detection\n",
    "from outliers import smirnov_grubbs as grubbs\n",
    "\n",
    "# Access to the localoutlierfactor for clustering\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# allows us to implement a train test split strategy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# access to the logistic regression class of Sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# access to the neural network model MLP Classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# classification metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# for use with CAP report\n",
    "from scipy import integrate\n",
    "\n",
    "# feature power transformation functions\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# normality tests\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import probplot\n",
    "\n",
    "# pip install imbalanced-learn (open anaconda prompt as admin)\n",
    "# sudo pip install imbalanced-learn (macos/linux)\n",
    "# pip install delayed (only do this if required)\n",
    "# This module is used for handling imbalanced data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Collections is a core python module. We wille use counter only for reporting\n",
    "from collections import Counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ntnu-testimon/paysim1/download\n",
    "# download archive.zip file and place in data/ folder \n",
    "data_df = pd.read_csv('data/archive.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362620, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fix some of the columns \n",
    "data_df = data_df.rename(columns={'oldbalanceOrg':'oldBalanceOrig', 'newbalanceOrig':'newBalanceOrig', \\\n",
    "                        'oldbalanceDest':'oldBalanceDest', 'newbalanceDest':'newBalanceDest'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Header\n",
    "This is a sample of 1 row with headers explanation:\n",
    "\n",
    "1,PAYMENT,1060.31,C429214117,1089.0,28.69,M1591654462,0.0,0.0,0,0\n",
    "\n",
    "step - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\n",
    "\n",
    "type - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.\n",
    "\n",
    "amount -\n",
    "amount of the transaction in local currency.\n",
    "\n",
    "nameOrig - customer who started the transaction\n",
    "\n",
    "oldbalanceOrg - initial balance before the transaction\n",
    "\n",
    "newbalanceOrig - new balance after the transaction\n",
    "\n",
    "nameDest - customer who is the recipient of the transaction\n",
    "\n",
    "oldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).\n",
    "\n",
    "newbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).\n",
    "\n",
    "isFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n",
    "\n",
    "isFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>dtypes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <td>1</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>9839.640000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nameOrig</th>\n",
       "      <td>C1231006815</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <td>170136.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <td>160296.360000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nameDest</th>\n",
       "      <td>M1979787155</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newBalanceDest</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <td>0</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sample   dtypes\n",
       "step                       1    int64\n",
       "type                 PAYMENT   object\n",
       "amount           9839.640000  float64\n",
       "nameOrig         C1231006815   object\n",
       "oldBalanceOrig 170136.000000  float64\n",
       "newBalanceOrig 160296.360000  float64\n",
       "nameDest         M1979787155   object\n",
       "oldBalanceDest      0.000000  float64\n",
       "newBalanceDest      0.000000  float64\n",
       "isFraud                    0    int64\n",
       "isFlaggedFraud             0    int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a quick view of the dataset\n",
    "tmp_df = data_df.head(1).T\n",
    "tmp_df.columns = ['sample']\n",
    "tmp_df['dtypes'] = data_df.dtypes\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do we have rows that have any null values?\n",
    "data_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to better understand our data\n",
    "\n",
    "col = 'type'\n",
    "series = data_df[col]\n",
    "tmp_df = pd.DataFrame(series.value_counts())\n",
    "tmp_df = tmp_df.T\n",
    "\n",
    "\n",
    "tmp_df.plot.bar(title=col,cmap=\"viridis\")\n",
    "plt.gcf().axes[0].yaxis.get_major_formatter().set_scientific(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6362620.000000\n",
       "mean      179861.903549\n",
       "std       603858.231463\n",
       "min            0.000000\n",
       "25%        13389.570000\n",
       "50%        74871.940000\n",
       "75%       208721.477500\n",
       "max     92445516.640000\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = data_df['amount']\n",
    "tmp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'type'}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = 'isFraud'\n",
    "series = data_df[col]\n",
    "tmp_df = pd.DataFrame(series.value_counts())\n",
    "tmp_df = tmp_df.T\n",
    "\n",
    "\n",
    "tmp_df.plot.bar(title=col,cmap=\"viridis\")\n",
    "plt.gcf().axes[0].yaxis.get_major_formatter().set_scientific(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>6354407</td>\n",
       "      <td>8213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1\n",
       "isFraud  6354407  8213"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There is a large imbalance between the two classes\n",
    "display(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's revisit the exploration but with respect to each payment type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "***PAYMENT***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>2151495.000000</td>\n",
       "      <td>13057.604660</td>\n",
       "      <td>12556.450186</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>4383.820000</td>\n",
       "      <td>9482.190000</td>\n",
       "      <td>17561.220000</td>\n",
       "      <td>238637.980000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count         mean          std      min         25%  \\\n",
       "amount 2151495.000000 13057.604660 12556.450186 0.020000 4383.820000   \n",
       "\n",
       "               50%          75%           max  \n",
       "amount 9482.190000 17561.220000 238637.980000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2151495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   isFraud\n",
       "0  2151495"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = 'type'\n",
    "tmp_s = data_df[col]\n",
    "tmp_list = tmp_s.unique()\n",
    "\n",
    "for i in tmp_list:\n",
    "    printmd(\"***\"+i+\"***\")\n",
    "    \n",
    "    tmp_df = data_df[data_df['type']==i]\n",
    "    display(tmp_df.describe()[['amount']].T)\n",
    "    \n",
    "    # fraud\n",
    "    display(pd.DataFrame(tmp_df['isFraud'].value_counts()))\n",
    "    \n",
    "    # merchant vs regular customer\n",
    "    \n",
    "    # origin\n",
    "    \n",
    "    orig = {'regular': tmp_df[tmp_df.nameOrig.str.contains('C')].drop_duplicates().shape[0], \n",
    "             'merchant': tmp_df[tmp_df.nameOrig.str.contains('M')].drop_duplicates().shape[0]}\n",
    "    dest = {'regular': tmp_df[tmp_df.nameDest.str.contains('C')].drop_duplicates().shape[0], \n",
    "             'merchant': tmp_df[tmp_df.nameDest.str.contains('M')].drop_duplicates().shape[0]}\n",
    "    \n",
    "    txn = [orig, dest]\n",
    "    \n",
    "    txn_df = pd.DataFrame(txn)\n",
    "    txn_df.index = [\"orig\",\"dest\"]\n",
    "    \n",
    "    display(txn_df)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like most frauds occured in Transfer and cash out and with regular customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at consistency of balance within transactions before and after\n",
    "\n",
    "# this should result to zero for a balanced transaction\n",
    "data_df['errorOrig'] = (data_df['newBalanceOrig']+data_df['amount'])-data_df['oldBalanceOrig']\n",
    "data_df['errorDest'] = (data_df['oldBalanceDest']+data_df['amount'])-data_df['newBalanceDest']\n",
    "\n",
    "# what is the percentage of transactions with non-balanced (non ZERO) transactions?\n",
    "print(\"% of orig txns with non zero error balance: \",data_df[data_df['errorOrig']!=0]['errorOrig'].count()/data_df['errorOrig'].shape[0])\n",
    "print(\"% of dest txns with non zero error balance: \",data_df[data_df['errorDest']!=0]['errorDest'].count()/data_df['errorDest'].shape[0])\n",
    "\n",
    "# how does it look like broken down by payment types?\n",
    "print()\n",
    "print(\"% of orig txns w/ non zero error balance by payment type\")\n",
    "tmp_df = data_df[data_df['errorOrig']!=0].groupby(['type']).count()['errorOrig']/data_df.groupby(['type']).count()['errorOrig']\n",
    "tmp_df = pd.DataFrame(tmp_df)\n",
    "display(tmp_df)\n",
    "\n",
    "print(\"% of dest txns w/ non zero error balance by payment type\")\n",
    "tmp_df = data_df[data_df['errorDest']!=0].groupby(['type']).count()['errorDest']/data_df.groupby(['type']).count()['errorDest']\n",
    "tmp_df = pd.DataFrame(tmp_df)\n",
    "display(tmp_df)\n",
    "\n",
    "# what about by fraud indicator?\n",
    "print(\"% of orig txns w/ non zero error balance by fraud ind\")\n",
    "tmp_df = data_df[data_df['errorOrig']!=0].groupby(['isFraud']).count()['errorOrig']/data_df.groupby(['isFraud']).count()['errorOrig']\n",
    "tmp_df = pd.DataFrame(tmp_df)\n",
    "display(tmp_df)\n",
    "\n",
    "print(\"% of dest txns w/ non zero error balance by fraud ind\")\n",
    "tmp_df = data_df[data_df['errorDest']!=0].groupby(['isFraud']).count()['errorDest']/data_df.groupby(['isFraud']).count()['errorDest']\n",
    "tmp_df = pd.DataFrame(tmp_df)\n",
    "display(tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems in general having non zero error balance between transactions does not indicate any fraud behavior except for destination accounts which has higher than normal of 64% identified as fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many unique fraud customers can be found in Cash out and transfer type transactions?\n",
    "data_df.groupby(['isFraud','type']).nunique()[['nameOrig','nameDest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = data_df[data_df['isFraud']==1]\n",
    "notfraud_df = data_df[data_df['isFraud']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any relationships within the customers and merchants that conducted fraud?\n",
    "\n",
    "fraudorig_set = set(fraud_df['nameOrig'].values) #convert series to array then set (unique) \n",
    "frauddest_set = set(fraud_df['nameDest'].values) #convert series to array then set (unique)\n",
    "fraudcombined_set = fraudorig_set.union(frauddest_set) #combine both into one set\n",
    "\n",
    "notfraudorig_set = set(notfraud_df['nameOrig'].values) #convert series to array then set (unique) \n",
    "notfrauddest_set = set(notfraud_df['nameDest'].values) #convert series to array then set (unique)\n",
    "notfraudcombined_set = notfraudorig_set.union(notfrauddest_set) #combine both into one set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total unique customer count: \", len(fraudcombined_set.union(notfraudcombined_set)))\n",
    "print(\"Customers involved in fraud: \",len(fraudcombined_set))\n",
    "print(\"Customers NOT involved in fraud: \",len(notfraudcombined_set))\n",
    "print(\"Originating Customers in Txns: \", len(fraudorig_set.union(notfraudorig_set)))\n",
    "print(\"Destination Customers in Txns: \", len(frauddest_set.union(notfrauddest_set)))\n",
    "print(\"Count of customers that originated in fraud transactions: \",len(fraudorig_set))\n",
    "print(\"How many of those customers are regular customers? \",len([i for i in fraudorig_set if 'C' in i]))\n",
    "print(\"How many of those customers are merchant customers? \", len([i for i in fraudorig_set if 'M' in i]))\n",
    "print(\"Count of customers that is the destination in fraud transactions: \",len(frauddest_set))\n",
    "print(\"How many of those customers are regular customers? \",len([i for i in frauddest_set if 'C' in i]))\n",
    "print(\"How many of those customers are merchant customers? \", len([i for i in frauddest_set if 'M' in i]))\n",
    "print(\"how many Fraud customers showed up in BOTH orig and dest? \", len(frauddest_set.intersection(fraudorig_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Did any fraud orig customers show up in legitimate transactions? \")\n",
    "print(\"How many transactions as originating customers? \", data_df[(data_df['nameOrig'].isin(fraudorig_set)) & (data_df['isFraud']==0)].shape[0])\n",
    "print(\"How many unique ids showed up as originating customers: \", len(fraudorig_set.intersection(notfraudorig_set)))\n",
    "print(\"How many transactions as destination customers? \", data_df[(data_df['nameDest'].isin(fraudorig_set)) & (data_df['isFraud']==0)].shape[0])\n",
    "print(\"How many unique ids showed up as destination customers: \", len(fraudorig_set.intersection(notfrauddest_set)))\n",
    "print(\"\")\n",
    "print(\"Did any fraud dest customers show up in legitimate transactions? \")\n",
    "print(\"How many transactions as originating customers? \", data_df[(data_df['nameOrig'].isin(frauddest_set)) & (data_df['isFraud']==0)].shape[0])\n",
    "print(\"How many unique ids showed up as originating customers: \", len(frauddest_set.intersection(notfraudorig_set)))\n",
    "print(\"How many transactions as destination customers? \", data_df[(data_df['nameDest'].isin(frauddest_set)) & (data_df['isFraud']==0)].shape[0])\n",
    "print(\"How many unique ids showed up as destination customers: \", len(frauddest_set.intersection(notfrauddest_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_df = pd.DataFrame()\n",
    "tmp_df['fraud'] = fraud_df.amount.describe().T\n",
    "tmp_df['notfraud'] = notfraud_df.amount.describe().T\n",
    "display(tmp_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we still have any null values?\n",
    "data_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "data_df['type_num'] = enc.fit_transform(data_df['type'])\n",
    "data_df['type_num'] = data_df['type_num'].apply(lambda x: np.int64(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the customer names since we won't be needing them for training\n",
    "\n",
    "training_df = data_df.drop(['nameOrig','nameDest','isFlaggedFraud','type','step'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "## via Clustering\n",
    "\n",
    "Unsupervised Outlier Detection using Local Outlier Factor (LOF)\n",
    "\n",
    "The anomaly score of each sample is called Local Outlier Factor. It measures the local deviation of density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. More precisely, locality is given by k-nearest neighbors, whose distance is used to estimate the local density. By comparing the local density of a sample to the local densities of its neighbors, one can identify samples that have a substantially lower density than their neighbors. These are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_df.isFraud\n",
    "X = training_df.drop(['isFraud'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsdfgsdfgsdfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lof_model = LocalOutlierFactor(n_neighbors=2)\n",
    "y_pred = lof_model.fit_predict(X)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lof works by tagging inliers with 1 and outliers by -1\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many outliers our unsupervised model detected (outliers are tagged as -1)\n",
    "\n",
    "tmp_df = pd.DataFrame(y_pred)\n",
    "tmp_df.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "negative_outlier_factor_ is The opposite LOF of the training samples. The higher, the more normal. Inliers tend to have a LOF score close to 1 (negative_outlier_factor_ close to -1), while outliers tend to have a larger LOF score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_model.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think of the negative_outlier_factor_ as our indicator on how 'far' the outlier is from the neighborhood densities.\n",
    "\n",
    "This demonstrates that we can use an unsupervised modeling approach to fraud detection in the event that we do not have yet substantial data on caught fraudsters. It is a good starting point to build our way towards building supervised models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## via Grubb's Test\n",
    "\n",
    "Grubbs’ Test is used to identify the presence of outliers in a dataset. To use this test, a dataset should be approximately normally distributed and have at least 7 observations. Grubbs's test is based on the assumption of **normality**. That is, one should first verify that the data can be reasonably approximated by a normal distribution before applying the Grubbs test.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Grubbs%27s_test\n",
    "\n",
    "**For purposes of demonstration we will only use ONE FEATURE to show case the tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will look at two classes of techniques for checking whether a sample of data is Gaussian:\n",
    "\n",
    "# Graphical Methods. These are methods for plotting the data and qualitatively evaluating whether the data looks Gaussian.\n",
    "# Statistical Tests. These are methods that calculate statistics on the data and quantify how likely it is that\n",
    "# the data was drawn from a Gaussian distribution. Methods of this type are often called normality tests.\n",
    "\n",
    "# via Graphical - We assume that plotting our data set would result to what would look like a 'normal' distribution\n",
    "\n",
    "# histogram - is an approximate representation of the distribution of numerical data\n",
    "\n",
    "series_tmp = training_df['amount'].copy()\n",
    "display(\"Before\")\n",
    "series_tmp.hist()\n",
    "plt.show()\n",
    "# you can see here that our distribution skews to the left which is different to the bellcurve of a normal/gaussian distribution\n",
    "\n",
    "# To address this, we use a power transformation and try to make our dataset look normal/gaussian\n",
    "# The Boxcox function accepts a lambda parameter that dictates what transformation to do\n",
    "# In this case a lambda value of 0 means it will do a log transformation to all of the data set\n",
    "boxcox_series_tmp = pd.Series(boxcox1p(series_tmp,0))\n",
    "display(\"After\")\n",
    "series_tmp.hist()\n",
    "plt.show()\n",
    "\n",
    "# You can see here that our data set is now more 'gaussian' like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Q-Q plot, or quantile-quantile plot, is a graphical tool to help us assess if\n",
    "# a set of data plausibly came from some theoretical distribution such as a Normal or exponential. \n",
    "\n",
    "display(\"Before\")\n",
    "probplot(series_tmp, dist=\"norm\", plot=plt)\n",
    "plt.show()\n",
    "\n",
    "# You can see that our data set does not completely fit our plot, so we apply the same power transformation\n",
    "\n",
    "display(\"After\")\n",
    "\n",
    "probplot(boxcox_series_tmp, dist=\"norm\", plot=plt)\n",
    "plt.show()\n",
    "\n",
    "# We plot the data set again and see a minor visual improvements to the qq plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The next tests validate by generating a statistic called p value \n",
    "# Technically this is called the null hypothesis, or H0. A threshold level is chosen called alpha, \n",
    "# typically 5% (or 0.05), that is used to interpret the p-value.\n",
    "\n",
    "# In the SciPy implementation of these tests, you can interpret the p value as follows.\n",
    "\n",
    "# p <= alpha: reject H0, not normal.\n",
    "# p > alpha: fail to reject H0, normal.\n",
    "\n",
    "\n",
    "\n",
    "print(\"Using Shapiro Normality Test\")\n",
    "print(\"Before: \")\n",
    "print(shapiro(series_tmp))\n",
    "\n",
    "print(\"After\")\n",
    "print(shapiro(boxcox_series_tmp))\n",
    "\n",
    "# The Shapiro-Wilk test evaluates a data sample and quantifies how likely it is that the data was drawn from a\n",
    "# Gaussian distribution, named for Samuel Shapiro and Martin Wilk.\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Using D’Agostino’s K^2 Normality Test\")\n",
    "print(\"Before: \")\n",
    "print(normaltest(series_tmp))\n",
    "\n",
    "print(\"After\")\n",
    "print(normaltest(boxcox_series_tmp))\n",
    "\n",
    "\n",
    "# The normal test AKA D’Agostino’s K^2 test calculates summary statistics from the data, namely kurtosis and skewness,\n",
    "# to determine if the data distribution departs from the normal distribution, named for Ralph D’Agostino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our statistical tests are telling us that our data set it not normally distributed, because of the resulting pvalue below .05 threshold despite our power transformations. On the other hand our graphical tests tells us that our data after the transformations are a bit more gaussian /normal like. No tests are perfect as well as no data is in reality 'completely' normally distributed. We can use this as decision point to move forward and treat our data set as gaussian like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test for normality first\n",
    "# transform to normal / guassian distribution to fit  if normality test fails\n",
    "# run grubb's test\n",
    "\n",
    "\n",
    "\n",
    "print(\"Our transformed data set length count: \")\n",
    "print(len(boxcox_series_tmp))\n",
    "grubbs_result = grubbs.test(boxcox_series_tmp, alpha=0.05)\n",
    "\n",
    "print(\"Our Grubbs test result length count: \")\n",
    "print(len(grubbs_result))\n",
    "\n",
    "print(\"Grubs test works by returning the dataset and removing the anomalies, you can see that we returned missing 1, which means we found 1 anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at what index was dropped by the test \n",
    "set(list(boxcox_series_tmp.index)).difference(set(list(grubbs_result.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what value did the test consider as outlier?\n",
    "boxcox_series_tmp[2736447]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE for oversampling\n",
    "SMOTE stands for Synthetic Minority Oversampling Technique. This is a statistical technique for increasing the number of cases in your dataset in a balanced way.\n",
    "\n",
    "Since our fraud dataset is imbalanced (low fraud cases), we will use oversampling to try to 'balance' the classes. This will results to more robust trained models that would be less prone to under or overfitting due to under or over representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "As our base model we will use a simple logistic regression as our starting point for developing our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we do a few things: 1) separate our data set into 30% and 70% splits\n",
    "# 70% will be used for as training data set\n",
    "# 30% will be used to test the resulting model\n",
    "# X represents our features\n",
    "# y reprsents our target variable (1 is most likely to apply to the company after the training)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X.columns \n",
    "# we keep the column names to be used later\n",
    "\n",
    "# Base model using all variables\n",
    "logreg_model = LogisticRegression(random_state=0)\n",
    "\n",
    "# Let's input our training data set and fit our model\n",
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick review of feature importance\n",
    "Using our trained logistic regression model, we will extract the computed coefficients and use that as basis for reporting the the effect of each feature to with respect to predicting the classification. A positive indicates the likelihood to result to a 1 while a negative value a 0. The value indicates the degree of impact to the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = logreg_model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d - %s, Score: %.6f' % (i,columns[i],v))\n",
    "\n",
    "# plot feature importance\n",
    "plt.bar([columns[x] for x in range(len(importance))], importance)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict against X_test\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's save our results in a variable for later use\n",
    "y_pred_lr = y_pred\n",
    "\n",
    "# How did our logistic regression perform?\n",
    "\n",
    "print(\"accuracy: \",accuracy_score(y_test,y_pred_lr))\n",
    "print(\"precision_score: \",precision_score(y_test,y_pred_lr))\n",
    "print(\"recall_score: \",recall_score(y_test,y_pred_lr))\n",
    "print(\"confusion matrix: \")\n",
    "confusion_matrix(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "lr_probs = y_pred_lr\n",
    "# keep probabilities for the positive outcome only\n",
    "#lr_probs = lr_probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic Regression')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "As our base model we will use a simple logistic regression as our starting point for developing our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation.\n",
    "\n",
    "\n",
    "\n",
    "nn_model = MLPClassifier(random_state=0)\n",
    "\n",
    "nn_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict against X_test\n",
    "y_pred = nn_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save our results in a variable for later use\n",
    "y_pred_nn = y_pred\n",
    "\n",
    "# How did our neural network model perform?\n",
    "\n",
    "print(\"accuracy: \",accuracy_score(y_test,y_pred_nn))\n",
    "print(\"precision_score: \",precision_score(y_test,y_pred_nn))\n",
    "print(\"recall_score: \",recall_score(y_test,y_pred_nn))\n",
    "print(\"confusion matrix: \")\n",
    "confusion_matrix(y_test,y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "lr_probs = y_pred_nn\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Neural Network: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Neural Network')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Neural Network\n",
    "Let's remodel the Neural Network but this time, let's filter out oldBalanceDest, newBalanceDest, and type_num since based on the feature importance review, these features contributed least to the predicting factor of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the features and create our revised train test dataset\n",
    "revised_X = X.drop(['oldBalanceDest','newBalanceDest','type_num'], axis=1)\n",
    "revised_X_train, revised_X_test, y_train, y_test = train_test_split(revised_X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation.\n",
    "\n",
    "\n",
    "\n",
    "revised_nn_model = MLPClassifier(random_state=0)\n",
    "\n",
    "revised_nn_model.fit(revised_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict against X_test\n",
    "y_pred = revised_nn_model.predict(revised_X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save our results in a variable for later use\n",
    "y_pred_revised_nn = y_pred\n",
    "\n",
    "# How did our neural network model perform?\n",
    "\n",
    "print(\"accuracy: \",accuracy_score(y_test,y_pred_revised_nn))\n",
    "print(\"precision_score: \",precision_score(y_test,y_pred_revised_nn))\n",
    "print(\"recall_score: \",recall_score(y_test,y_pred_revised_nn))\n",
    "print(\"confusion matrix: \")\n",
    "confusion_matrix(y_test,y_pred_revised_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a no skill prediction (majority class)\n",
    "ns_probs = [0 for _ in range(len(y_test))]\n",
    "lr_probs = y_pred_revised_nn\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Neural Network: ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "# calculate roc curves\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Revised Neural Network')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's summarize our findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_list = []\n",
    "tmp_dict = {\"accuracy\":accuracy_score(y_test,y_pred_lr), \"precision\":precision_score(y_test,y_pred_lr), \"recall\":recall_score(y_test,y_pred_lr),\"roc auc\": roc_auc_score(y_test,y_pred_lr)}\n",
    "tmp_list.append(tmp_dict)\n",
    "tmp_dict = {\"accuracy\":accuracy_score(y_test,y_pred_nn), \"precision\":precision_score(y_test,y_pred_nn), \"recall\":recall_score(y_test,y_pred_nn),\"roc auc\":roc_auc_score(y_test,y_pred_nn)}\n",
    "tmp_list.append(tmp_dict)\n",
    "tmp_dict = {\"accuracy\":accuracy_score(y_test,y_pred_revised_nn), \"precision\":precision_score(y_test,y_pred_revised_nn), \"recall\":recall_score(y_test,y_pred_revised_nn),\"roc auc\":roc_auc_score(y_test,y_pred_revised_nn)}\n",
    "tmp_list.append(tmp_dict)\n",
    "\n",
    "scores_df = pd.DataFrame(tmp_list)\n",
    "scores_df.index = ['LogisticRegression','NeuralNetworks','RevisedNeuralNetworks']\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we choose our champion model? IT DEPENDS\n",
    "\n",
    "Fraud use cases are a tricky challenge to tackle given its nature of being inherently 'hidden'. It always implies that the dataset would always be imbalanced and that we would never have the complete picture of all the possible fraud indicators and that everytime we catch fraudsters they will inevitably change behavior to find other fraudulent techniques that have not yet been detected.\n",
    "\n",
    "Its important to be anchored on the objective of the business and how it is affected by fraud. Depending on  the type of industry, a business may be affected by the cost of a fraud transactions, the cost of investigating a fraud case, the cost to entity's reputation, or the cost to the customer experience. Looking at all these factors will help one decide which model is based used that greatly cater's to the business need.\n",
    "\n",
    "Given our curret use case, we **recommend the 2nd model (In this case, Neural Network)** which has a high precision as we have a high volume transactional business which means when investigating fraudulent activities, we want to limit the capture of false positives to control the cost of investigating fraud (which is normally high) and to minimize the impact to our customers (its annoying to be accused of fraud if you are actually a legit customer and have your transactions frozen)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Accuracy Profile (CAP) or Lorenz Curve\n",
    "\n",
    "CAP popularly called the ‘Cumulative Accuracy Profile’ is used in the performance evaluation of the classification model. It helps us to understand and conclude about the robustness of the classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def capcurve(y_values, y_preds_proba):\n",
    "    num_pos_obs = np.sum(y_values)\n",
    "    num_count = len(y_values)\n",
    "    rate_pos_obs = float(num_pos_obs) / float(num_count)\n",
    "    ideal = pd.DataFrame({'x':[0,rate_pos_obs,1],'y':[0,1,1]})\n",
    "    xx = np.arange(num_count) / float(num_count - 1)\n",
    "    \n",
    "    y_cap = np.c_[y_values,y_preds_proba]\n",
    "    y_cap_df_s = pd.DataFrame(data=y_cap)\n",
    "    y_cap_df_s = y_cap_df_s.sort_values([1], ascending=False).reset_index(level = y_cap_df_s.index.names, drop=True)\n",
    "    \n",
    "    #print(y_cap_df_s.head(20))\n",
    "    \n",
    "    yy = np.cumsum(y_cap_df_s[0]) / float(num_pos_obs)\n",
    "    yy = np.append([0], yy[0:num_count-1]) #add the first curve point (0,0) : for xx=0 we have yy=0\n",
    "    \n",
    "    percent = 0.5\n",
    "    row_index = int(np.trunc(num_count * percent))\n",
    "    \n",
    "    val_y1 = yy[row_index]\n",
    "    val_y2 = yy[row_index+1]\n",
    "    if val_y1 == val_y2:\n",
    "        val = val_y1*1.0\n",
    "    else:\n",
    "        val_x1 = xx[row_index]\n",
    "        val_x2 = xx[row_index+1]\n",
    "        val = val_y1 + ((val_x2 - percent)/(val_x2 - val_x1))*(val_y2 - val_y1)\n",
    "    \n",
    "    sigma_ideal = 1 * xx[num_pos_obs - 1 ] / 2 + (xx[num_count - 1] - xx[num_pos_obs]) * 1\n",
    "    sigma_model = integrate.simps(yy,xx)\n",
    "    sigma_random = integrate.simps(xx,xx)\n",
    "    \n",
    "    ar_value = (sigma_model - sigma_random) / (sigma_ideal - sigma_random)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.subplots(nrows = 1, ncols = 1)\n",
    "\n",
    "    \n",
    "    ax.plot(ideal['x'],ideal['y'], color='grey', label='Perfect Model')\n",
    "    ax.plot(xx,yy, color='red', label='Revised Neural Network Model')\n",
    "    ax.plot(xx,xx, color='blue', label='Random Model')\n",
    "    ax.plot([percent, percent], [0.0, val], color='green', linestyle='--', linewidth=1)\n",
    "    ax.plot([0, percent], [val, val], color='green', linestyle='--', linewidth=1, label=str(val*100)+'% of positive obs at '+str(percent*100)+'%')\n",
    "    \n",
    "    plt.xlim(0, 1.02)\n",
    "    plt.ylim(0, 1.25)\n",
    "    plt.title(\"CAP Curve - a_r value =\"+str(ar_value))\n",
    "    plt.xlabel('% of the data')\n",
    "    plt.ylabel('% of positive obs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Let's store the pred probability for use later when we call the CAP function\n",
    "revised_y_pred_proba = revised_nn_model.predict_proba(X=revised_X_test)\n",
    "\n",
    "# Let's cal lthe cap curve function. What does this is pass the y_test (which contains our target classification\n",
    "# as well as the predicted probabilities. The intention is to chart our CAP and see what is the optimal approach to \n",
    "# acting on our scored transaction list \n",
    "capcurve(y_test,revised_y_pred_proba[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chart tells us that if we only investigate the top 50% of the scored transaction list, we will already get 97.56% of all fraudulent cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create our white list. This white list will be the list of transactions that we will spend resources to investigate\n",
    "# as they are the most probable fraud cases based on our revised neural network model\n",
    "\n",
    "save_whitelist_df = revised_X_test.copy() # Let's create a dataframe of the test dataset\n",
    "save_whitelist_df['y_pred_proba'] = revised_y_pred_proba[:,1] # store the probability to be a fraud case\n",
    "save_whitelist_df['y_pred'] = y_pred_nn # add the predictions of our revised neural network\n",
    "save_whitelist_df = save_whitelist_df.sort_values('y_pred_proba',ascending=False) # sort with highest to lowest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's get our cut off and filter to the final list and save to a CSV File\n",
    "\n",
    "percentage = .49 # Let's use 49% since based on the chart we already hit the optimal cutoff before 50%\n",
    "cutoff = int(save_whitelist_df.shape[0]*percentage) # will get the absolute count of 49% of total rows\n",
    "print(\"Our cutoff value is \", cutoff)\n",
    "save_whitelist_df = save_whitelist_df[0:cutoff] # we filter until the cutoff\n",
    "save_whitelist_df.to_csv(\"fraud_revised_nn.csv\") # Filter only to the predcted and save our CSV file\n",
    "print(\"We predict \",save_whitelist_df['y_pred'].sum(), \" fraud cases out of \", revised_X_test.shape[0], \" transactions.\")\n",
    "save_whitelist_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset to try\n",
    "- https://www.kaggle.com/c/ieee-fraud-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
